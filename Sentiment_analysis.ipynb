{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642662b9",
   "metadata": {},
   "source": [
    "# Code adapted from\n",
    "* https://dzlab.github.io/dltips/en/pytorch/torchtext-datasets/ to use custom dataset\n",
    "* https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb to use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10330d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_WEIGHT= 0.12744395919192275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b8aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c290b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy',\n",
    "                  tokenizer_language = 'en_core_web_sm',\n",
    "                  preprocessing = generate_bigrams)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1d58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128#64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train, val, test = data.TabularDataset.splits(\n",
    "    path='./data', train='Train.csv',\n",
    "    validation='Val.csv', test='Test.csv', format='csv',\n",
    "    fields=[('text', TEXT),(None, None), ('label', LABEL)],\n",
    "    skip_header = True)# ignore helpfulness column\n",
    "    # columns are Text, helpfulness, and rating\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, val, test), batch_sizes=(BATCH_SIZE,BATCH_SIZE,BATCH_SIZE),\n",
    "    sort_key=lambda x: len(x.text), device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf810c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 50_000\n",
    "\n",
    "TEXT.build_vocab(train, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e310f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "        \n",
    "        #pooled = [batch size, embedding_dim]\n",
    "                \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba5a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a147424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc, rounded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7703a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    preds=[]\n",
    "    labels=[]\n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc, rounded_preds = binary_accuracy(predictions, batch.label)\n",
    "        preds.extend(rounded_preds.detach().to('cpu').numpy())\n",
    "        labels.extend(batch.label.detach().to('cpu').numpy())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b70f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    preds=[]\n",
    "    labels=[]\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc, rounded_preds = binary_accuracy(predictions, batch.label)\n",
    "            preds.extend(rounded_preds.detach().to('cpu').numpy())\n",
    "            labels.extend(batch.label.detach().to('cpu').numpy())\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea80e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcff7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from tqdm.notebook import  tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70e3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train_model(adam=0,lr=0.001,epochs=5):\n",
    "    # use base adam if adam <=0.5 otherwise use adamW with weight decay\n",
    "    model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr=lr) if adam<=0.5 else optim.AdamW(model.parameters(),lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([CLASS_WEIGHT]))\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = round(epochs)\n",
    "    #best_valid_loss = float('inf')\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "        \n",
    "\n",
    "        train_loss, train_acc, t_preds, t_labels = train(model, train_iter, optimizer, criterion)\n",
    "        valid_loss, valid_acc, v_preds, v_labels = evaluate(model, val_iter, criterion)\n",
    "        f1 = f1_score(v_labels, v_preds, average=\"macro\")\n",
    "       \n",
    "        #print('gt: {}'.format(np.unique(v_labels)))\n",
    "        #print('preds: {}'.format(np.unique(v_preds)))\n",
    "        \n",
    "       # if valid_loss < best_valid_loss:\n",
    "       #     best_valid_loss = valid_loss\n",
    "       #     torch.save(model.state_dict(), 'sentiment.pt')\n",
    "        \n",
    "        #print(f'Epoch: {epoch+1:02}')# | Epoch Time: {epoch_mins}m {epoch_secs}s'\n",
    "        #print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print('F1: {}'.format(f1))\n",
    "    print('Precision: {}'.format(precision_score(v_labels, v_preds, average=\"macro\")))\n",
    "    print('Recall: {}'.format(recall_score(v_labels, v_preds, average=\"macro\")))\n",
    "    print(f'Total Train time for {N_EPOCHS} epochs: {epoch_mins}m {epoch_secs}s')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    return f1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8809f1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cfe040b95448aeac23c2a925677175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4522696133913147\n",
      "Precision: 0.4128803328167061\n",
      "Recall: 0.49996707385334693\n",
      "Total Train time for 1 epochs: 1m 52s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4522696133913147"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ccd089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   adam    |  epochs   |    lr     |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebb37c47360477eb635ec9bfc255177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7882371187235566\n",
      "Precision: 0.8161964810237439\n",
      "Recall: 0.7674657193664922\n",
      "Total Train time for 9 epochs: 15m 25s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 0.1915  \u001b[0m | \u001b[0m 8.599   \u001b[0m | \u001b[0m 0.02189 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a95cab523b418bb2529dbecd847af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7928496176800536\n",
      "Precision: 0.8118243428464358\n",
      "Recall: 0.7774828229444901\n",
      "Total Train time for 10 epochs: 17m 15s\n",
      "------------------------------------------------------------\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7928  \u001b[0m | \u001b[95m 0.7854  \u001b[0m | \u001b[95m 10.02   \u001b[0m | \u001b[95m 0.01364 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1a23c7767a4463bbb26b04f04d63f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7878713895836493\n",
      "Precision: 0.8121770342329044\n",
      "Recall: 0.7692258705982158\n",
      "Total Train time for 10 epochs: 17m 4s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7879  \u001b[0m | \u001b[0m 0.2765  \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 0.04791 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd61bc6e99b46929ef40268ceabb169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7772568324321255\n",
      "Precision: 0.8135290736931383\n",
      "Recall: 0.7524752544181976\n",
      "Total Train time for 9 epochs: 15m 1s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7773  \u001b[0m | \u001b[0m 0.7809  \u001b[0m | \u001b[0m 9.317   \u001b[0m | \u001b[0m 0.04597 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b3503893ba462e8a7ca3399773fb53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7902685023582146\n",
      "Precision: 0.8094852418559227\n",
      "Recall: 0.7747745531803376\n",
      "Total Train time for 10 epochs: 16m 51s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7903  \u001b[0m | \u001b[0m 0.6363  \u001b[0m | \u001b[0m 10.08   \u001b[0m | \u001b[0m 0.02645 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eed9fb5e2f74cba8f7aabd6a430ff11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4522859270290394\n",
      "Precision: 0.4128850702846733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaston\\Anaconda3\\envs\\sentan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n",
      "Total Train time for 10 epochs: 17m 3s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4523  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.27   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061165bb13dd4b699916d41a23036f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7910446601448151\n",
      "Precision: 0.8099496949159654\n",
      "Recall: 0.7757464380054713\n",
      "Total Train time for 10 epochs: 17m 16s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.791   \u001b[0m | \u001b[0m 0.646   \u001b[0m | \u001b[0m 9.836   \u001b[0m | \u001b[0m 0.02526 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91a26a5d9da4e1ca32f23d44834af97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4522859270290394\n",
      "Precision: 0.4128850702846733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaston\\Anaconda3\\envs\\sentan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n",
      "Total Train time for 10 epochs: 16m 57s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.4523  \u001b[0m | \u001b[0m 0.2939  \u001b[0m | \u001b[0m 9.891   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820a5238fd784ce29becca0b29daf8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7873713494650416\n",
      "Precision: 0.8206142150987369\n",
      "Recall: 0.763776091487717\n",
      "Total Train time for 10 epochs: 16m 49s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7874  \u001b[0m | \u001b[0m 0.8328  \u001b[0m | \u001b[0m 9.83    \u001b[0m | \u001b[0m 0.006959\u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9c632e2e994493ac326108aa0c9534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7793408204249126\n",
      "Precision: 0.8249105271184313\n",
      "Recall: 0.7502916534835335\n",
      "Total Train time for 4 epochs: 6m 48s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7793  \u001b[0m | \u001b[0m 0.7424  \u001b[0m | \u001b[0m 4.485   \u001b[0m | \u001b[0m 0.03939 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82edf0316ced4aebb212041e1b266645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7874759622879242\n",
      "Precision: 0.8124598504189589\n",
      "Recall: 0.7684350795796738\n",
      "Total Train time for 10 epochs: 16m 46s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7875  \u001b[0m | \u001b[0m 0.4007  \u001b[0m | \u001b[0m 10.43   \u001b[0m | \u001b[0m 0.05    \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1b2f0059b944188fe5a3ee117239d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.76270956893236\n",
      "Precision: 0.8370420930036653\n",
      "Recall: 0.7248895552494232\n",
      "Total Train time for 5 epochs: 8m 34s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 0.6257  \u001b[0m | \u001b[0m 5.063   \u001b[0m | \u001b[0m 0.03354 \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'adam':(0,1),'lr': (0.00001, 0.05), 'epochs': (3, 12)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=train_model,\n",
    "    pbounds=pbounds,\n",
    "    random_state=SEED,\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=3,\n",
    "    n_iter=9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3313e1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "\t{'target': 0.7882371187235566, 'params': {'adam': 0.1915194503788923, 'epochs': 8.598978939358487, 'lr': 0.021892009672965652}}\n",
      "Iteration 1: \n",
      "\t{'target': 0.7928496176800536, 'params': {'adam': 0.7853585837137692, 'epochs': 10.019782273069232, 'lr': 0.013636904338079254}}\n",
      "Iteration 2: \n",
      "\t{'target': 0.7878713895836493, 'params': {'adam': 0.2764642551430967, 'epochs': 10.216849597815173, 'lr': 0.047907386290648425}}\n",
      "Iteration 3: \n",
      "\t{'target': 0.7772568324321255, 'params': {'adam': 0.7809393108395023, 'epochs': 9.31704812255748, 'lr': 0.04597356133128867}}\n",
      "Iteration 4: \n",
      "\t{'target': 0.7902685023582146, 'params': {'adam': 0.6362641870940634, 'epochs': 10.083466398155759, 'lr': 0.026447852578768315}}\n",
      "Iteration 5: \n",
      "\t{'target': 0.4522859270290394, 'params': {'adam': 1.0, 'epochs': 10.265971123103421, 'lr': 1e-05}}\n",
      "Iteration 6: \n",
      "\t{'target': 0.7910446601448151, 'params': {'adam': 0.6460486094712681, 'epochs': 9.835740241925215, 'lr': 0.02525844927997214}}\n",
      "Iteration 7: \n",
      "\t{'target': 0.4522859270290394, 'params': {'adam': 0.29389044878666404, 'epochs': 9.890812394920287, 'lr': 1e-05}}\n",
      "Iteration 8: \n",
      "\t{'target': 0.7873713494650416, 'params': {'adam': 0.8327533559613003, 'epochs': 9.829788378425325, 'lr': 0.0069585427952602455}}\n",
      "Iteration 9: \n",
      "\t{'target': 0.7793408204249126, 'params': {'adam': 0.7423548737973155, 'epochs': 4.484955438355787, 'lr': 0.03939002186521719}}\n",
      "Iteration 10: \n",
      "\t{'target': 0.7874759622879242, 'params': {'adam': 0.40074087306487893, 'epochs': 10.426606459866525, 'lr': 0.05}}\n",
      "Iteration 11: \n",
      "\t{'target': 0.76270956893236, 'params': {'adam': 0.6256841482138339, 'epochs': 5.062685239207843, 'lr': 0.03353532718415342}}\n"
     ]
    }
   ],
   "source": [
    "bayes_values=[]\n",
    "bayes_params=[]\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    bayes_values.append(res['target'])\n",
    "    bayes_params.append(f\"Iteration {i}\")\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d35b6c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'target': 0.7928496176800536, 'params': {'adam': 0.7853585837137692, 'epochs': 10.019782273069232, 'lr': 0.013636904338079254}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "plt.ylim([0.4, 0.82])\n",
    "fig.suptitle('Bayesian Optimization runs for F1 Score')\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "ax.bar(bayes_params, bayes_values)\n",
    "print('best params: {}'.format(optimizer.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace4f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_save(adam=0,lr=0.001,epochs=5):\n",
    "    # use base adam if adam <=0.5 otherwise use adamW with weight decay\n",
    "    model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=lr) if adam<=0.5 else optim.AdamW(model.parameters(),lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([CLASS_WEIGHT]))\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = round(epochs)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_valid_f1 = 0\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, t_preds, t_labels = train(model, train_iter, optimizer, criterion)\n",
    "        valid_loss, valid_acc, v_preds, v_labels = evaluate(model, val_iter, criterion)\n",
    "        \n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        f1 = f1_score(v_labels, v_preds, average=\"macro\")\n",
    "        print('F1: {}'.format(f1))\n",
    "        print('Precision: {}'.format(precision_score(v_labels, v_preds, average=\"macro\")))\n",
    "        print('Recall: {}'.format(recall_score(v_labels, v_preds, average=\"macro\")))\n",
    "        if f1 > best_valid_f1:\n",
    "            best_valid_f1 = f1\n",
    "            torch.save(model.state_dict(), 'sentiment.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d8715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4d8a37f95b4b719c4052246d8e10ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.774827482830577\n",
      "Precision: 0.8438028274591864\n",
      "Recall: 0.7375984860713973\n",
      "Epoch: 01 | Epoch Time: 1m 43s\n",
      "\tTrain Loss: 0.086 | Train Acc: 83.86%\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 88.97%\n",
      "F1: 0.7837667886561469\n",
      "Precision: 0.8302397710598322\n",
      "Recall: 0.7541330689458301\n",
      "Epoch: 02 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.072 | Train Acc: 85.00%\n",
      "\t Val. Loss: 0.333 |  Val. Acc: 88.95%\n",
      "F1: 0.7879235833256676\n",
      "Precision: 0.8257099368771059\n",
      "Recall: 0.762043608221715\n",
      "Epoch: 03 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.070 | Train Acc: 85.29%\n",
      "\t Val. Loss: 0.328 |  Val. Acc: 88.97%\n",
      "F1: 0.7887187822705499\n",
      "Precision: 0.8223309561184158\n",
      "Recall: 0.7648937443925012\n",
      "Epoch: 04 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.070 | Train Acc: 85.45%\n",
      "\t Val. Loss: 0.360 |  Val. Acc: 88.91%\n",
      "F1: 0.7860414154342197\n",
      "Precision: 0.8261085325961486\n",
      "Recall: 0.7591493932511375\n",
      "Epoch: 05 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.070 | Train Acc: 85.54%\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 88.92%\n",
      "F1: 0.7813282306833309\n",
      "Precision: 0.8240098937561783\n",
      "Recall: 0.7534388135047296\n",
      "Epoch: 06 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.069 | Train Acc: 85.58%\n",
      "\t Val. Loss: 0.384 |  Val. Acc: 88.75%\n",
      "F1: 0.793619305748841\n",
      "Precision: 0.8054969470847708\n",
      "Recall: 0.7832833552656\n",
      "Epoch: 07 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.070 | Train Acc: 85.55%\n",
      "\t Val. Loss: 0.427 |  Val. Acc: 88.56%\n",
      "F1: 0.7769050416670109\n",
      "Precision: 0.8334323312709386\n",
      "Recall: 0.7437020411936377\n",
      "Epoch: 08 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.069 | Train Acc: 85.57%\n",
      "\t Val. Loss: 0.335 |  Val. Acc: 88.83%\n",
      "F1: 0.7807767009342406\n",
      "Precision: 0.8236758955034134\n",
      "Recall: 0.7528145937793863\n",
      "Epoch: 09 | Epoch Time: 1m 43s\n",
      "\tTrain Loss: 0.070 | Train Acc: 85.54%\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 88.73%\n",
      "F1: 0.7819654172462489\n",
      "Precision: 0.8237172426288566\n",
      "Recall: 0.7544636869202752\n",
      "Epoch: 10 | Epoch Time: 1m 44s\n",
      "\tTrain Loss: 0.070 | Train Acc: 85.51%\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 88.76%\n"
     ]
    }
   ],
   "source": [
    "model = train_model_save(adam= optimizer.max['params']['adam'], lr=optimizer.max['params']['lr'],\n",
    "                 epochs=optimizer.max['params']['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93f903e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7914951466869681\n",
      "Precision: 0.8030659396188283\n",
      "Recall: 0.7814061245798196\n",
      "Test Loss: 1.091 | Test Acc: 88.43%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('sentiment.pt'))\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "test_loss, test_acc, t_preds, t_labels = evaluate(model, test_iter, criterion)\n",
    "f1 = f1_score(t_labels, t_preds, average=\"macro\")\n",
    "print('F1: {}'.format(f1))\n",
    "print('Precision: {}'.format(precision_score(t_labels, t_preds, average=\"macro\")))\n",
    "print('Recall: {}'.format(recall_score(t_labels, t_preds, average=\"macro\")))\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e66b3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = generate_bigrams([tok.text for tok in nlp.tokenizer(sentence)])\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47fde58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"this is bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78b006ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"I am so impressed with this item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c4284",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Some words are not processed correctly: with f1 score tuning sentiments seem to be reversed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"Tokenized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec727370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prediction\"]= df[\"Text\"].map(lambda x:predict_sentiment(model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94faf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Scaled_Prediction\"]= df.apply(lambda row:(row['Prediction']*row['Helpfulness']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb238c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0375e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212352bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
