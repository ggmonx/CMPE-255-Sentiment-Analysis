{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642662b9",
   "metadata": {},
   "source": [
    "# Code adapted from\n",
    "* https://dzlab.github.io/dltips/en/pytorch/torchtext-datasets/ to use custom dataset\n",
    "* https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb to use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b8aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c290b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy',\n",
    "                  tokenizer_language = 'en_core_web_sm',\n",
    "                  preprocessing = generate_bigrams)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1d58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128#64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train, val, test = data.TabularDataset.splits(\n",
    "    path='./data', train='Train.csv',\n",
    "    validation='Val.csv', test='Test.csv', format='csv',\n",
    "    fields=[('text', TEXT),(None, None), ('label', LABEL)],\n",
    "    skip_header = True)# ignore helpfulness column\n",
    "    # columns are Text, helpfulness, and rating\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, val, test), batch_sizes=(BATCH_SIZE,BATCH_SIZE,BATCH_SIZE),\n",
    "    sort_key=lambda x: len(x.text), device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf810c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 50_000\n",
    "\n",
    "TEXT.build_vocab(train, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e310f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "        \n",
    "        #pooled = [batch size, embedding_dim]\n",
    "                \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba5a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a147424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc, rounded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7703a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    preds=[]\n",
    "    labels=[]\n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc, rounded_preds = binary_accuracy(predictions, batch.label)\n",
    "        preds.extend(rounded_preds.detach().to('cpu').numpy())\n",
    "        labels.extend(batch.label.detach().to('cpu').numpy())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b70f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    preds=[]\n",
    "    labels=[]\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc, rounded_preds = binary_accuracy(predictions, batch.label)\n",
    "            preds.extend(rounded_preds.detach().to('cpu').numpy())\n",
    "            labels.extend(batch.label.detach().to('cpu').numpy())\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea80e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcff7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from tqdm.notebook import  tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train_model(adam=0,lr=0.001,epochs=5):\n",
    "    # use base adam if adam <=0.5 otherwise use adamW with weight decay\n",
    "    model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr=lr) if adam<=0.5 else optim.AdamW(model.parameters(),lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = round(epochs)\n",
    "    #best_valid_loss = float('inf')\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "        \n",
    "\n",
    "        train_loss, train_acc, t_preds, t_labels = train(model, train_iter, optimizer, criterion)\n",
    "        valid_loss, valid_acc, v_preds, v_labels = evaluate(model, val_iter, criterion)\n",
    "        f1 = f1_score(v_labels, v_preds, average=\"macro\")\n",
    "       \n",
    "        #print('gt: {}'.format(np.unique(v_labels)))\n",
    "        #print('preds: {}'.format(np.unique(v_preds)))\n",
    "        \n",
    "       # if valid_loss < best_valid_loss:\n",
    "       #     best_valid_loss = valid_loss\n",
    "       #     torch.save(model.state_dict(), 'sentiment.pt')\n",
    "        \n",
    "        #print(f'Epoch: {epoch+1:02}')# | Epoch Time: {epoch_mins}m {epoch_secs}s'\n",
    "        #print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print('F1: {}'.format(f1))\n",
    "    print('Precision: {}'.format(precision_score(v_labels, v_preds, average=\"macro\")))\n",
    "    print('Recall: {}'.format(recall_score(v_labels, v_preds, average=\"macro\")))\n",
    "    print(f'Total Train time for {N_EPOCHS} epochs: {epoch_mins}m {epoch_secs}s')\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    return f1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8809f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7321615005274933\n",
      "Precision: 0.7979085425996042\n",
      "Recall: 0.6993520708456674\n",
      "Total Train time for 1 epochs: 1m 41s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7321615005274933"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ccd089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   adam    |  epochs   |    lr     |\n",
      "-------------------------------------------------------------\n",
      "F1: 0.7910539301684277\n",
      "Precision: 0.774177770979543\n",
      "Recall: 0.8133883653864507\n",
      "Total Train time for 9 epochs: 15m 35s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7911  \u001b[0m | \u001b[0m 0.1915  \u001b[0m | \u001b[0m 8.599   \u001b[0m | \u001b[0m 0.02189 \u001b[0m |\n",
      "F1: 0.7921287963594777\n",
      "Precision: 0.7779814290509286\n",
      "Recall: 0.8098067280408396\n",
      "Total Train time for 10 epochs: 17m 11s\n",
      "------------------------------------------------------------\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7921  \u001b[0m | \u001b[95m 0.7854  \u001b[0m | \u001b[95m 10.02   \u001b[0m | \u001b[95m 0.01364 \u001b[0m |\n",
      "F1: 0.7903696900962036\n",
      "Precision: 0.7750797204622906\n",
      "Recall: 0.809959569829691\n",
      "Total Train time for 10 epochs: 17m 15s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7904  \u001b[0m | \u001b[0m 0.2765  \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 0.04791 \u001b[0m |\n",
      "F1: 0.7941959654498039\n",
      "Precision: 0.7855128781634907\n",
      "Recall: 0.8040351362680025\n",
      "Total Train time for 6 epochs: 10m 10s\n",
      "------------------------------------------------------------\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7942  \u001b[0m | \u001b[95m 0.8759  \u001b[0m | \u001b[95m 6.22    \u001b[0m | \u001b[95m 0.02505 \u001b[0m |\n",
      "F1: 0.7932058931911014\n",
      "Precision: 0.7769570191607222\n",
      "Recall: 0.8143532287416404\n",
      "Total Train time for 9 epochs: 15m 8s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7932  \u001b[0m | \u001b[0m 0.6835  \u001b[0m | \u001b[0m 9.414   \u001b[0m | \u001b[0m 0.01852 \u001b[0m |\n",
      "F1: 0.7856920037617496\n",
      "Precision: 0.7625321998823611\n",
      "Recall: 0.8223876281518032\n",
      "Total Train time for 6 epochs: 10m 13s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7857  \u001b[0m | \u001b[0m 0.8831  \u001b[0m | \u001b[0m 6.044   \u001b[0m | \u001b[0m 0.0251  \u001b[0m |\n",
      "F1: 0.7942047415202709\n",
      "Precision: 0.7808390566332053\n",
      "Recall: 0.8106210241558023\n",
      "Total Train time for 9 epochs: 15m 13s\n",
      "------------------------------------------------------------\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7942  \u001b[0m | \u001b[95m 0.9167  \u001b[0m | \u001b[95m 8.552   \u001b[0m | \u001b[95m 0.01461 \u001b[0m |\n",
      "F1: 0.7843412558832863\n",
      "Precision: 0.7605777199697541\n",
      "Recall: 0.8229840548797611\n",
      "Total Train time for 11 epochs: 18m 33s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7843  \u001b[0m | \u001b[0m 0.8882  \u001b[0m | \u001b[0m 11.43   \u001b[0m | \u001b[0m 0.01324 \u001b[0m |\n",
      "F1: 0.7949380350388444\n",
      "Precision: 0.7789072522271513\n",
      "Recall: 0.8156550635638371\n",
      "Total Train time for 4 epochs: 19m 24s\n",
      "------------------------------------------------------------\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.7949  \u001b[0m | \u001b[95m 0.2683  \u001b[0m | \u001b[95m 3.795   \u001b[0m | \u001b[95m 0.008889\u001b[0m |\n",
      "F1: 0.7905283052427547\n",
      "Precision: 0.772201627182039\n",
      "Recall: 0.8156119344908621\n",
      "Total Train time for 7 epochs: 12m 27s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7905  \u001b[0m | \u001b[0m 0.1682  \u001b[0m | \u001b[0m 6.615   \u001b[0m | \u001b[0m 0.004821\u001b[0m |\n",
      "F1: 0.794083303379743\n",
      "Precision: 0.7764386860980679\n",
      "Recall: 0.8177099435441959\n",
      "Total Train time for 3 epochs: 5m 29s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7941  \u001b[0m | \u001b[0m 0.4823  \u001b[0m | \u001b[0m 3.114   \u001b[0m | \u001b[0m 0.0182  \u001b[0m |\n",
      "F1: 0.7828945815007287\n",
      "Precision: 0.7602369717722688\n",
      "Recall: 0.81854616045025\n",
      "Total Train time for 4 epochs: 7m 21s\n",
      "------------------------------------------------------------\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7829  \u001b[0m | \u001b[0m 0.7424  \u001b[0m | \u001b[0m 4.485   \u001b[0m | \u001b[0m 0.03939 \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'adam':(0,1),'lr': (0.00001, 0.05), 'epochs': (3, 12)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=train_model,\n",
    "    pbounds=pbounds,\n",
    "    random_state=SEED,\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=5,\n",
    "    n_iter=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3313e1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "\t{'target': 0.7910539301684277, 'params': {'adam': 0.1915194503788923, 'epochs': 8.598978939358487, 'lr': 0.021892009672965652}}\n",
      "Iteration 1: \n",
      "\t{'target': 0.7921287963594777, 'params': {'adam': 0.7853585837137692, 'epochs': 10.019782273069232, 'lr': 0.013636904338079254}}\n",
      "Iteration 2: \n",
      "\t{'target': 0.7903696900962036, 'params': {'adam': 0.2764642551430967, 'epochs': 10.216849597815173, 'lr': 0.047907386290648425}}\n",
      "Iteration 3: \n",
      "\t{'target': 0.7941959654498039, 'params': {'adam': 0.8759326347420947, 'epochs': 6.2203554296208, 'lr': 0.0250547463249177}}\n",
      "Iteration 4: \n",
      "\t{'target': 0.7932058931911014, 'params': {'adam': 0.6834629351721363, 'epochs': 9.414318242846102, 'lr': 0.018518835231971842}}\n",
      "Iteration 5: \n",
      "\t{'target': 0.7856920037617496, 'params': {'adam': 0.8830584948954096, 'epochs': 6.044450951635342, 'lr': 0.025103841296604194}}\n",
      "Iteration 6: \n",
      "\t{'target': 0.7942047415202709, 'params': {'adam': 0.9167281615240777, 'epochs': 8.552157187446348, 'lr': 0.014613657887185764}}\n",
      "Iteration 7: \n",
      "\t{'target': 0.7843412558832863, 'params': {'adam': 0.8881846621228777, 'epochs': 11.432080647081115, 'lr': 0.013241672714464778}}\n",
      "Iteration 8: \n",
      "\t{'target': 0.7949380350388444, 'params': {'adam': 0.26825798565095393, 'epochs': 3.795299442287926, 'lr': 0.008888927807508653}}\n",
      "Iteration 9: \n",
      "\t{'target': 0.7905283052427547, 'params': {'adam': 0.168244435377489, 'epochs': 6.615186743326149, 'lr': 0.004821331731130997}}\n",
      "Iteration 10: \n",
      "\t{'target': 0.794083303379743, 'params': {'adam': 0.4823406418236492, 'epochs': 3.114488707478259, 'lr': 0.01820113790957291}}\n",
      "Iteration 11: \n",
      "\t{'target': 0.7828945815007287, 'params': {'adam': 0.7423548737973155, 'epochs': 4.484955438355787, 'lr': 0.03939002186521719}}\n"
     ]
    }
   ],
   "source": [
    "bayes_values=[]\n",
    "bayes_params=[]\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    bayes_values.append(res['target'])\n",
    "    bayes_params.append(f\"Iteration {i}\")\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d35b6c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'target': 0.7949380350388444, 'params': {'adam': 0.26825798565095393, 'epochs': 3.795299442287926, 'lr': 0.008888927807508653}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "plt.ylim([0.779, 0.795])\n",
    "fig.suptitle('Bayesian Optimization runs for F1 Score')\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "ax.bar(bayes_params, bayes_values)\n",
    "print('best params: {}'.format(optimizer.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ace4f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_save(adam=0,lr=0.001,epochs=5):\n",
    "    # use base adam if adam <=0.5 otherwise use adamW with weight decay\n",
    "    model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=lr) if adam<=0.5 else optim.AdamW(model.parameters(),lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = round(epochs)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_valid_f1 = 0\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, t_preds, t_labels = train(model, train_iter, optimizer, criterion)\n",
    "        valid_loss, valid_acc, v_preds, v_labels = evaluate(model, val_iter, criterion)\n",
    "        \n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        f1 = f1_score(v_labels, v_preds, average=\"macro\")\n",
    "        print('F1: {}'.format(f1))\n",
    "        print('Precision: {}'.format(precision_score(v_labels, v_preds, average=\"macro\")))\n",
    "        print('Recall: {}'.format(recall_score(v_labels, v_preds, average=\"macro\")))\n",
    "        if f1 > best_valid_f1:\n",
    "            best_valid_f1 = f1\n",
    "            torch.save(model.state_dict(), 'sentiment.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45d8715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dde84f7bf74d728d23518fa0278c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7935477134470768\n",
      "Precision: 0.7736405458699798\n",
      "Recall: 0.8216740604569269\n",
      "Epoch: 01 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.319 | Train Acc: 87.05%\n",
      "\t Val. Loss: 1.115 |  Val. Acc: 87.06%\n",
      "F1: 0.7992317756188959\n",
      "Precision: 0.7873363799156717\n",
      "Recall: 0.8133940192155238\n",
      "Epoch: 02 | Epoch Time: 1m 42s\n",
      "\tTrain Loss: 0.274 | Train Acc: 89.06%\n",
      "\t Val. Loss: 1.185 |  Val. Acc: 87.93%\n",
      "F1: 0.7972328869179227\n",
      "Precision: 0.7989828354643067\n",
      "Recall: 0.795521169347366\n",
      "Epoch: 03 | Epoch Time: 1m 43s\n",
      "\tTrain Loss: 0.266 | Train Acc: 89.43%\n",
      "\t Val. Loss: 1.140 |  Val. Acc: 88.41%\n",
      "F1: 0.7903502491860268\n",
      "Precision: 0.7698335870529356\n",
      "Recall: 0.8200086609604819\n",
      "Epoch: 04 | Epoch Time: 1m 45s\n",
      "\tTrain Loss: 0.261 | Train Acc: 89.57%\n",
      "\t Val. Loss: 1.253 |  Val. Acc: 86.79%\n"
     ]
    }
   ],
   "source": [
    "model = train_model_save(adam= optimizer.max['params']['adam'], lr=optimizer.max['params']['lr'],\n",
    "                 epochs=optimizer.max['params']['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93f903e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.197 | Test Acc: 87.98%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('sentiment.pt'))\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "test_loss, test_acc, t_preds, t_labels = evaluate(model, test_iter, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e66b3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = generate_bigrams([tok.text for tok in nlp.tokenizer(sentence)])\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47fde58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"this is mediocre at best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "78b006ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.469452950521372e-06"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"I am so impressed with this item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c4284",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Some words are not processed correctly: with f1 score tuning sentiments seem to be reversed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9bf4f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['daughter', 'wanted', 'book', 'price', 'Amazo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bought', 'zoku', 'quick', 'pop', 'daughterr'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['shortage', 'pop', 'recipes', 'available', 'f...</td>\n",
       "      <td>2.059259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['book', 'must', 'get', 'Zoku', 'also', 'highl...</td>\n",
       "      <td>1.855556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cookbook', 'great', 'really', 'enjoyed', 're...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Helpfulness  Rating\n",
       "0  ['daughter', 'wanted', 'book', 'price', 'Amazo...     1.000000       1\n",
       "1  ['bought', 'zoku', 'quick', 'pop', 'daughterr'...     1.000000       1\n",
       "2  ['shortage', 'pop', 'recipes', 'available', 'f...     2.059259       1\n",
       "3  ['book', 'must', 'get', 'Zoku', 'also', 'highl...     1.855556       1\n",
       "4  ['cookbook', 'great', 'really', 'enjoyed', 're...     1.000000       1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"Tokenized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec727370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prediction\"]= df[\"Text\"].map(lambda x:predict_sentiment(model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c94faf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Scaled_Prediction\"]= df.apply(lambda row:(row['Prediction']*row['Helpfulness']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb238c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Scaled_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['daughter', 'wanted', 'book', 'price', 'Amazo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.246930e-18</td>\n",
       "      <td>2.246930e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bought', 'zoku', 'quick', 'pop', 'daughterr'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.309569e-19</td>\n",
       "      <td>2.309569e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['shortage', 'pop', 'recipes', 'available', 'f...</td>\n",
       "      <td>2.059259</td>\n",
       "      <td>1</td>\n",
       "      <td>5.153782e-05</td>\n",
       "      <td>1.061297e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['book', 'must', 'get', 'Zoku', 'also', 'highl...</td>\n",
       "      <td>1.855556</td>\n",
       "      <td>1</td>\n",
       "      <td>1.337574e-26</td>\n",
       "      <td>2.481943e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cookbook', 'great', 'really', 'enjoyed', 're...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.742831e-14</td>\n",
       "      <td>9.742831e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Helpfulness  Rating  \\\n",
       "0  ['daughter', 'wanted', 'book', 'price', 'Amazo...     1.000000       1   \n",
       "1  ['bought', 'zoku', 'quick', 'pop', 'daughterr'...     1.000000       1   \n",
       "2  ['shortage', 'pop', 'recipes', 'available', 'f...     2.059259       1   \n",
       "3  ['book', 'must', 'get', 'Zoku', 'also', 'highl...     1.855556       1   \n",
       "4  ['cookbook', 'great', 'really', 'enjoyed', 're...     1.000000       1   \n",
       "\n",
       "     Prediction  Scaled_Prediction  \n",
       "0  2.246930e-18       2.246930e-18  \n",
       "1  2.309569e-19       2.309569e-19  \n",
       "2  5.153782e-05       1.061297e-04  \n",
       "3  1.337574e-26       2.481943e-26  \n",
       "4  9.742831e-14       9.742831e-14  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f8af0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e0375e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    455204\n",
       "0     96478\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212352bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
