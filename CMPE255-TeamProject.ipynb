{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from unzipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention: You need to unzip \"reviews_Home_and_Kitchen_5.json\" to get \"Home_and_Kitchen_5.json\"\n",
    "# set USE SMALL SUBSET if using sample data\n",
    "USE_SMALL_SUBSET = False\n",
    "path = \"data.json\" if USE_SMALL_SUBSET else \"Home_and_Kitchen_5.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' IGNORE WHEN running from data json\\nwith open(\\'data.json\\', \\'w\\') as outfile:\\n        for i in data[:100_000]:\\n            json.dump(i, outfile)\\n            outfile.write(\"\\n\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" IGNORE WHEN running from data json\n",
    "with open('data.json', 'w') as outfile:\n",
    "        for i in data[:100_000]:\n",
    "            json.dump(i, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proccessed_data = []\n",
    "proccessed_data = [ [dics[\"reviewText\"], dics[\"helpful\"], dics['overall'] ] for dics in data]\n",
    "# for dics in data:\n",
    "#     line = []\n",
    "#     line.append(dics[\"reviewText\"])\n",
    "#     line.append(dics[\"helpful\"])\n",
    "#     line.append(dics['overall'])\n",
    "#     proccessed_data.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking number of unique words in the data set before preproccessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Filtering Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_set = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_punctuation(text):\n",
    "    no_punct=[words for words in text if words not in punct_set]\n",
    "    words_wo_punct=''.join(no_punct)\n",
    "    return words_wo_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in proccessed_data:\n",
    "    data[0] = filter_punctuation(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 481174 samples and 53739451 outcomes>\n"
     ]
    }
   ],
   "source": [
    "fdist_wo_punct = FreqDist()\n",
    "for line in proccessed_data:\n",
    "    for word in line[0].split():\n",
    "        fdist_wo_punct[word.lower()] += 1\n",
    "print(fdist_wo_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of unique words went down to 481174 from 838417 after removing the puncuation :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gaston\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in proccessed_data:\n",
    "    data[0] = word_tokenize(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2780773),\n",
       " ('i', 1606253),\n",
       " ('and', 1557137),\n",
       " ('a', 1438350),\n",
       " ('to', 1425398),\n",
       " ('it', 1387669),\n",
       " ('is', 876047),\n",
       " ('of', 835434),\n",
       " ('this', 759706),\n",
       " ('for', 728397),\n",
       " ('in', 612086),\n",
       " ('that', 551863),\n",
       " ('my', 467378),\n",
       " ('with', 446288),\n",
       " ('you', 432856),\n",
       " ('have', 428896),\n",
       " ('on', 425902),\n",
       " ('but', 399901),\n",
       " ('not', 355774),\n",
       " ('so', 322844),\n",
       " ('as', 308031),\n",
       " ('was', 305702),\n",
       " ('are', 304115),\n",
       " ('one', 270744),\n",
       " ('use', 243819),\n",
       " ('they', 241978),\n",
       " ('be', 239917),\n",
       " ('its', 239749),\n",
       " ('very', 232904),\n",
       " ('or', 218627),\n",
       " ('like', 202988),\n",
       " ('just', 200785),\n",
       " ('if', 194194),\n",
       " ('up', 193151),\n",
       " ('out', 187099),\n",
       " ('can', 183018),\n",
       " ('great', 179985),\n",
       " ('at', 177328),\n",
       " ('these', 176098),\n",
       " ('when', 175176),\n",
       " ('all', 171446),\n",
       " ('had', 166292),\n",
       " ('them', 164924),\n",
       " ('well', 161751),\n",
       " ('would', 161676),\n",
       " ('will', 158631),\n",
       " ('more', 147408),\n",
       " ('good', 145571),\n",
       " ('from', 144893),\n",
       " ('than', 139689)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_wo_punct.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Stop Words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word.lower() not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in proccessed_data:\n",
    "    data[0] = remove_stopwords(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating scaling values for helpfulness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sntmtl_label(help_list):\n",
    "    if help_list[1] == 0:\n",
    "        return 1.0\n",
    "#         return \"neutral\"\n",
    "    return 1+(1.1*(help_list[0] / help_list[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in proccessed_data:\n",
    "    data[1] = create_sntmtl_label(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating sentimental labels for overall ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rating_sntmtl(rating: float):\n",
    "    if rating <=3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in proccessed_data:\n",
    "    line[2] = create_rating_sntmtl(line[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Panda dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(proccessed_data, columns=['Text','Helpfulness','Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[daughter, wanted, book, price, Amazon, best, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bought, zoku, quick, pop, daughterr, zoku, qu...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[shortage, pop, recipes, available, free, web,...</td>\n",
       "      <td>2.059259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[book, must, get, Zoku, also, highly, recommen...</td>\n",
       "      <td>1.855556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[cookbook, great, really, enjoyed, reviewing, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Helpfulness  Rating\n",
       "0  [daughter, wanted, book, price, Amazon, best, ...     1.000000       1\n",
       "1  [bought, zoku, quick, pop, daughterr, zoku, qu...     1.000000       1\n",
       "2  [shortage, pop, recipes, available, free, web,...     2.059259       1\n",
       "3  [book, must, get, Zoku, also, highly, recommen...     1.855556       1\n",
       "4  [cookbook, great, really, enjoyed, reviewing, ...     1.000000       1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Tokenized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['daughter', 'wanted', 'book', 'price', 'Amazo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bought', 'zoku', 'quick', 'pop', 'daughterr'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['shortage', 'pop', 'recipes', 'available', 'f...</td>\n",
       "      <td>2.059259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['book', 'must', 'get', 'Zoku', 'also', 'highl...</td>\n",
       "      <td>1.855556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cookbook', 'great', 'really', 'enjoyed', 're...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Helpfulness  Rating\n",
       "0  ['daughter', 'wanted', 'book', 'price', 'Amazo...     1.000000       1\n",
       "1  ['bought', 'zoku', 'quick', 'pop', 'daughterr'...     1.000000       1\n",
       "2  ['shortage', 'pop', 'recipes', 'available', 'f...     2.059259       1\n",
       "3  ['book', 'must', 'get', 'Zoku', 'also', 'highl...     1.855556       1\n",
       "4  ['cookbook', 'great', 'really', 'enjoyed', 're...     1.000000       1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Tokenized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551682, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"]= df[\"Text\"].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split is 60 20 20\n",
    "X_train, X_test, __, _ = train_test_split(df[['Text',\"Helpfulness\",\"Rating\"]], df[['Rating']], test_size=0.20, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, __, _ = train_test_split(X_train, __, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"./data/Train.csv\",index=False)\n",
    "X_val.to_csv(\"./data/Val.csv\",index=False)\n",
    "X_test.to_csv(\"./data/Test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
